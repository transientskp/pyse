import os
import unittest
import numpy as np
import warnings
from pathlib import Path
import pytest
from scipy.signal import fftconvolve
from scipy.stats import ttest_1samp
import pandas as pd

from astropy.wcs import WCS
from astropy.coordinates import SkyCoord
import astropy.units as u

from sourcefinder.accessors import sourcefinder_image_from_accessor, writefits
from sourcefinder.accessors.fitsimage import FitsImage
from .conftest import DATAPATH
from sourcefinder.testutil.decorators import requires_data, duration
import sourcefinder.accessors
from sourcefinder import image
from sourcefinder.gaussian import gaussian
from sourcefinder.config import Conf, ImgConf, ExportSettings
from sourcefinder.utility.sourceparams import SourceParams

# Numbers for `SourceParameters.testAllParameters` unit test.
MAX_BIAS = 5.0
STD_MAX_BIAS_FACTOR = 2.0
NUMBER_INSERTED = 3969
TRUE_PEAK_BRIGHTNESS = 1063.67945065
TRUE_DECONV_SMAJ = 2.0 * 5.5956 / 2.0
TRUE_DECONV_SMIN = 0.5 * 4.6794 / 2.0
TRUE_DECONV_BPA = -0.5 * (-49.8)

# These are measured from the file CORRELATED_NOISE.FITS.
# BG_MEAN = numpy.mean(sourcefinder_image_from_accessor(FitsFile("CORRELATED_NOISE.FITS")).data)
BG_MEAN = -0.0072340798975137829
# BG_STD = numpy.std(sourcefinder_image_from_accessor(FitsFile("CORRELATED_NOISE.FITS")).data)
BG_STD = 5.3480336747739079


class SourceParameters(unittest.TestCase):
    """
    This is a set of unit tests in the presence of correlated noise.
    That noise was generated by convolving uncorrelated noise with the
    dirty beam of a certain VLA observation. 3969 identical extended
    sources on a regular 63*63 grid were convolved with the clean beam.
    The accuracy of the deconvolution algorithm, i.e., the deconvolution
    of the fitted parameters from the clean beam. is tested.
    It also tests the accuracy of the peak brightness measurements.
    Bias up to 5 sigma is allowed.
    Note that oversampling of the synthesized beam will likely reduce bias,
    i.e. pixellation effects will become apparent.
    """
    def setUp(self):
        fitsfile = sourcefinder.accessors.open(
            os.path.join(DATAPATH, "deconvolved.fits")
        )
        img = image.ImageData(fitsfile.data, fitsfile.beam, fitsfile.wcs)

        # This is quite subtle. We bypass any possible flaws in the
        # kappa, sigma clipping algorithm by supplying a background
        # level and noise map. In this way we make sure that any
        # possible biases in the measured source parameters cannot
        # come from biases in the background level. The peak brightnesses,
        # in particular, can be biased low if the background levels
        # are biased high. The background and noise levels supplied
        # here are the true values.

        extraction_results = img.extract(
            det=10.0,
            anl=6.0,
            noisemap=np.ma.array(BG_STD * np.ones((2048, 2048))),
            bgmap=np.ma.array(BG_MEAN * np.ones((2048, 2048))),
        )
        self.number_sources = len(extraction_results)

        peak_brightnesses = []
        deconv_smajaxes = []
        deconv_sminaxes = []
        deconv_bpas = []

        for source in extraction_results:
            peak_brightnesses.append([source.peak.value, source.peak.error])
            deconv_smajaxes.append(
                [source.smaj_dc.value, source.smaj_dc.error]
            )
            deconv_sminaxes.append(
                [source.smin_dc.value, source.smin_dc.error]
            )
            deconv_bpas.append([source.theta_dc.value, source.theta_dc.error])

        self.peak_brightnesses = np.array(peak_brightnesses)
        self.deconv_smajaxes = np.array(deconv_smajaxes)
        self.deconv_sminaxes = np.array(deconv_sminaxes)
        self.deconv_bpas = np.array(deconv_bpas)

    @duration(100)
    @requires_data(os.path.join(DATAPATH, "deconvolved.fits"))
    def testAllParameters(self):
        # Test all deconvolved
        self.assertEqual(
            np.where(np.isnan(self.deconv_smajaxes), 1, 0).sum(), 0
        )
        self.assertEqual(
            np.where(np.isnan(self.deconv_sminaxes), 1, 0).sum(), 0
        )
        self.assertEqual(np.where(np.isnan(self.deconv_bpas), 1, 0).sum(), 0)

        # Test number of sources
        self.assertEqual(self.number_sources, NUMBER_INSERTED)

        # Test peak brightnesses
        peak_weights = 1.0 / self.peak_brightnesses[:, 1] ** 2
        sum_peak_weights = np.sum(peak_weights)
        av_peak = np.sum(
            self.peak_brightnesses[:, 0] * peak_weights / sum_peak_weights
        )
        av_peak_err = 1 / np.sqrt(sum_peak_weights)
        signif_dev_peak = (TRUE_PEAK_BRIGHTNESS - av_peak) / av_peak_err
        self.assertTrue(np.abs(signif_dev_peak) < MAX_BIAS)

        # Test major axes
        smaj_weights = 1.0 / self.deconv_smajaxes[:, 1] ** 2
        sum_smaj_weights = np.sum(smaj_weights)
        av_smaj = np.sum(
            self.deconv_smajaxes[:, 0] * smaj_weights / sum_smaj_weights
        )
        av_smaj_err = 1 / np.sqrt(sum_smaj_weights)
        signif_dev_smaj = (TRUE_DECONV_SMAJ - av_smaj) / av_smaj_err
        self.assertTrue(np.abs(signif_dev_smaj) < MAX_BIAS)

        # Test minor axes
        smin_weights = 1.0 / self.deconv_sminaxes[:, 1] ** 2
        sum_smin_weights = np.sum(smin_weights)
        av_smin = np.sum(
            self.deconv_sminaxes[:, 0] * smin_weights / sum_smin_weights
        )
        av_smin_err = 1 / np.sqrt(sum_smin_weights)
        signif_dev_smin = (TRUE_DECONV_SMIN - av_smin) / av_smin_err
        self.assertTrue(np.abs(signif_dev_smin) < MAX_BIAS)

        # Test position angles
        bpa_weights = 1.0 / self.deconv_bpas[:, 1] ** 2
        sum_bpa_weights = np.sum(bpa_weights)
        av_bpa = np.sum(self.deconv_bpas[:, 0] * bpa_weights / sum_bpa_weights)
        av_bpa_err = 1 / np.sqrt(sum_bpa_weights)
        signif_dev_bpa = (TRUE_DECONV_BPA - av_bpa) / av_bpa_err
        self.assertTrue(np.abs(signif_dev_bpa) < MAX_BIAS)


def create_beam_kernel(
    peak_brightness,
    beam: tuple,
    size=15,
    xoffset=0.0,
    yoffset=0.0,
):
    """Create a peak-normalized elliptical Gaussian kernel for the
    clean beam."""

    smaj_pix, smin_pix, theta_rad = beam
    # Best to have a centrosymmetric grid, which requires size to be odd.
    if size % 2 == 0:
        size -= 1

    # Creates indices starting at 0, ending at size - 1.
    x, y = np.indices((size, size), dtype=float)

    center = (size - 1) // 2
    # This should ensure that both x.min() and y.min() are integers and equal.
    x -= center
    y -= center

    assert x.mean() == 0
    assert y.mean() == 0

    gaussian_function = gaussian(
        peak_brightness, xoffset, yoffset, smaj_pix, smin_pix, theta_rad
    )
    gaussian_profile = gaussian_function(x, y)

    x_min = x.min()
    y_min = y.min()

    # Return the Gaussian profile.
    # Also return the minimum values of x and y, since they should match
    # with the lower bounds of the subimage.
    return gaussian_profile, x_min, y_min


@pytest.fixture
def generate_artificial_image(tmp_path):
    """Generate FITS image with either resolved or unresolved sources and save
    ground truth."""

    @requires_data(os.path.join(DATAPATH, "Dirty_beam", "psf.fits"))
    def _generate(
        psf_fits_path: Path = os.path.join(DATAPATH, "Dirty_beam", "psf.fits"),
        output_fits_path: Path = tmp_path / "image_unresolved.fits",
        output_truth_path: Path = tmp_path / "truth_unresolved.h5",
        output_size=4096,
        peak_brightness=50.0,
        num_sources=167_281,
        unresolved=True,
    ):

        psf_fits = FitsImage(psf_fits_path)
        psf_im = sourcefinder_image_from_accessor(psf_fits)
        psf_imdata = psf_im.data.data

        # Convolve white noise with PSF
        white_noise = np.random.normal(0, 1, (output_size, output_size))
        # Transpose the data before working with it.
        psf_kernel = psf_imdata / np.sum(psf_imdata)
        corr_noise = fftconvolve(white_noise, psf_kernel, mode="same")

        # Normalize to mean 0, std 1 Jy/beam
        corr_noise = (corr_noise - np.mean(corr_noise)) / np.std(corr_noise)

        coords = []

        # Round num_sources to the nearest squared integer.
        ns_sqrt = round(np.sqrt(num_sources))
        ns_sqi = ns_sqrt**2

        source_spacing = round(output_size / (ns_sqrt + 1))
        # Space around the center of the Gaussian.
        space_ar = (source_spacing - 1) // 2

        for x in np.linspace(
            space_ar + 1,
            output_size - space_ar - 1,
            num=ns_sqrt,
            endpoint=True,
        ):
            for y in np.linspace(
                space_ar + 1,
                output_size - space_ar - 1,
                num=ns_sqrt,
                endpoint=True,
            ):

                offset_x = np.random.uniform(-0.5, 0.5)
                offset_y = np.random.uniform(-0.5, 0.5)

                roundx = round(x)
                roundy = round(y)

                pos_x = roundx + offset_x
                pos_y = roundy + offset_y

                if unresolved:
                    source_to_be_inserted, x_min, y_min = create_beam_kernel(
                        peak_brightness,
                        psf_im.beam,
                        size=source_spacing,
                        xoffset=offset_x,
                        yoffset=offset_y,
                    )
                else:
                    # Fill in later
                    pass

                subimage_indices = (
                    slice(roundx - space_ar, roundx + space_ar + 1),
                    slice(roundy - space_ar, roundy + space_ar + 1),
                )

                # Only add ground-truth values and insert sources if all tests
                # pass.
                all_tests_pass = 1

                try:
                    lowest_x_subimage = subimage_indices[0].start - roundx
                    assert lowest_x_subimage == x_min
                except AssertionError:
                    warnings.warn(
                        (
                            f"Lower x-bounds not aligned, {lowest_x_subimage = } ,"
                            f"{x_min = }"
                        )
                    )
                    all_tests_pass = 0

                try:
                    lowest_y_subimage = subimage_indices[1].start - roundy
                    assert lowest_y_subimage == y_min
                except AssertionError:
                    warnings.warn(
                        (
                            f"Lower y-bounds not aligned, {lowest_y_subimage = } ,"
                            f"{y_min = }"
                        )
                    )
                    all_tests_pass = 0

                try:
                    assert (
                        subimage_indices[0].stop - subimage_indices[0].start
                        == source_to_be_inserted.shape[0]
                    )
                    try:
                        assert (
                            subimage_indices[1].stop
                            - subimage_indices[1].start
                            == source_to_be_inserted.shape[1]
                        )
                    except AssertionError:
                        subimage_width_y = (
                            subimage_indices[1].stop
                            - subimage_indices[1].start
                        )
                        source_inserted_width_y = source_to_be_inserted.shape[
                            1
                        ]
                        warnings.warn(
                            (
                                f"{subimage_width_y = }, "
                                f"{source_inserted_width_y = }: "
                                "assertion failed."
                            )
                        )
                        all_tests_pass = 0

                except AssertionError:
                    subimage_width_x = (
                        subimage_indices[0].stop - subimage_indices[0].start
                    )
                    source_inserted_width_x = source_to_be_inserted.shape[0]
                    warnings.warn(
                        (
                            f"{subimage_width_x = }, "
                            f"{source_inserted_width_x = }: "
                            "assertion failed."
                        )
                    )
                    all_tests_pass = 0

                if all_tests_pass:
                    # Insert the source in the image, i.e. add it to the
                    # correlated noise.
                    corr_noise[subimage_indices] += source_to_be_inserted
                    coords.append((pos_x, pos_y))

        # Construct output header
        out_header = psf_fits.header.copy()
        out_header["NAXIS1"] = output_size
        out_header["NAXIS2"] = output_size
        out_header["CRPIX1"] = output_size // 2
        out_header["CRPIX2"] = output_size // 2

        wcs_out = WCS(out_header)

        print()
        print(f"Number of sources intended to be inserted = {num_sources}")
        print(
            (
                "Number of sources intended to be inserted matching a square "
                f"regular grid = {ns_sqi}"
            )
        )
        coords_px = np.array(coords)
        print(f"Number of sources actually inserted = {len(coords)}")
        coords_full = np.zeros((ns_sqi, 4))
        coords_full[:, 0] = coords_px[:, 0]  # x
        coords_full[:, 1] = coords_px[:, 1]  # y
        coords_full[:, 2] = 0  # freq index
        coords_full[:, 3] = 0  # stokes index

        coords_world = wcs_out.wcs_pix2world(coords_full, 0)

        truth_df = pd.DataFrame(
            {
                SourceParams.PEAK: peak_brightness * np.ones(len(coords_px)),
                SourceParams.X: coords_px[:, 0],
                SourceParams.Y: coords_px[:, 1],
                SourceParams.RA: coords_world[:, 0],
                SourceParams.DEC: coords_world[:, 1],
            }
        )

        # Save ground truth to HDF5
        truth_df.to_hdf(output_truth_path, key="truth", mode="w")

        writefits(corr_noise, output_fits_path, header=out_header)

    return _generate


def test_measured_vectorized_forced_beam(
    tmp_path, generate_artificial_image, min_pvalue=0.01
):
    """
    Compare source parameters from vectorized source measurements with forced
    beam to its corresponding ground truth values. This includes checks for
    biases. The artificial images are regenerated for each test run.
    Consequently, if you run these tests often enough, it will fail at some
    point, depending on the value of `min_pvalue` and `MAX_BIAS`. We will
    scale the latter with the square root of the ratio of the number of
    inserted sources over the number of inserted sources in the
    `SourceParameters.testAllParameters`
    test.
    """
    image_path = tmp_path / "image_unresolved.fits"
    truth_path = tmp_path / "truth_unresolved.h5"

    num_sources = 167_281

    SCALED_MAX_BIAS = MAX_BIAS * np.sqrt(num_sources / NUMBER_INSERTED)

    generate_artificial_image(
        output_fits_path=image_path,
        output_truth_path=truth_path,
        peak_brightness=20.0,
        num_sources=num_sources,
    )

    conf = Conf(
        image=ImgConf(
            allow_multiprocessing=False,
            vectorized=True,
            back_size_x=256,
            back_size_y=256,
        ),
        export=ExportSettings(),
    )
    fits_img = FitsImage(image_path)
    img = sourcefinder_image_from_accessor(fits_img, conf=conf)

    source_params_df = img.extract(
        det=12.0,
        anl=8.0,
        noisemap=np.ma.array(np.ones(img.data.shape)),
        bgmap=np.ma.array(np.zeros(img.data.shape)),
        force_beam=True,
        reconvert=False,
    )
    number_measured_sources = source_params_df.shape[0]

    # Load the ground truth source parameters into a Pandas DataFrame.
    truth_df = pd.read_hdf(truth_path, key="truth")

    assert number_measured_sources == truth_df.shape[0], (
        f"Number of measured sources {number_measured_sources} "
        f"does not match number of ground truth_df sources {truth_df.shape[0]}"
    )

    # Match sources by sky position
    sky_meas = SkyCoord(
        ra=source_params_df[SourceParams.RA].to_numpy() * u.deg,
        dec=source_params_df[SourceParams.DEC].to_numpy() * u.deg,
    )
    sky_truth_df = SkyCoord(
        ra=truth_df[SourceParams.RA].to_numpy() * u.deg,
        dec=truth_df[SourceParams.DEC].to_numpy() * u.deg,
    )

    idx, _, _ = sky_meas.match_to_catalog_sky(sky_truth_df)

    _, counts = np.unique(idx, return_counts=True)
    duplicates = np.sum(counts > 1)
    assert (
        duplicates == 0
    ), f"{duplicates} measured sources were matched to multiple true sources."

    true_x = truth_df[SourceParams.X].to_numpy()[idx]
    true_y = truth_df[SourceParams.Y].to_numpy()[idx]

    measured_x = source_params_df[SourceParams.X].to_numpy()
    measured_y = source_params_df[SourceParams.Y].to_numpy()

    # Compute normalized residuals
    norm_x_resid = (measured_x - true_x) / source_params_df[
        SourceParams.X_ERR
    ].to_numpy()
    norm_y_resid = (measured_y - true_y) / source_params_df[
        SourceParams.Y_ERR
    ].to_numpy()

    # Check that the mean of the position is not biased
    p_x = ttest_1samp(norm_x_resid, popmean=0)[1]
    assert p_x > min_pvalue, f"X position not centred: p={p_x :.3f}"
    p_y = ttest_1samp(norm_y_resid, popmean=0)[1]
    assert p_y > min_pvalue, f"Y position not centred: p={p_y :.3f}"

    # Check standard deviation is ~1 (roughly Gaussian-distributed errors)
    std_x = np.std(norm_x_resid)
    std_y = np.std(norm_y_resid)
    assert 1.0 / STD_MAX_BIAS_FACTOR < std_x < STD_MAX_BIAS_FACTOR, (
        f"X errors not " f"realistic:td={std_x :.3f}"
    )
    assert 1.0 / STD_MAX_BIAS_FACTOR < std_y < STD_MAX_BIAS_FACTOR, (
        f"Y errors not realistic: " f"std={std_y :.3f}"
    )

    # Extract matched true values
    true_ra = truth_df[SourceParams.RA].to_numpy()[idx]
    true_dec = truth_df[SourceParams.DEC].to_numpy()[idx]

    measured_ra = source_params_df[SourceParams.RA].to_numpy()
    measured_dec = source_params_df[SourceParams.DEC].to_numpy()

    measured_ra_err = source_params_df[SourceParams.RA_ERR].to_numpy()
    measured_dec_err = source_params_df[SourceParams.DEC_ERR].to_numpy()

    # Compute normalized residuals
    norm_ra_resid = (measured_ra - true_ra) / measured_ra_err
    norm_dec_resid = (measured_dec - true_dec) / measured_dec_err

    # Check that the mean of the position is not biased
    p_ra = ttest_1samp(norm_ra_resid, popmean=0)[1]
    assert p_ra > min_pvalue, f"Right ascension not centred: p={p_ra :.3f}"
    p_dec = ttest_1samp(norm_dec_resid, popmean=0)[1]
    assert (
        p_dec > min_pvalue
    ), f"DEC residuals deviate too much from normal: p={p_dec :.3f}"

    # Check standard deviation is ~1 (roughly Gaussian-distributed errors)
    std_ra = np.std(norm_ra_resid)
    std_dec = np.std(norm_dec_resid)

    assert 1.0 / STD_MAX_BIAS_FACTOR < std_ra < STD_MAX_BIAS_FACTOR, (
        f"RA errors not " f"realistic: std={std_ra :.3f}"
    )
    assert 1.0 / STD_MAX_BIAS_FACTOR < std_dec < STD_MAX_BIAS_FACTOR, (
        f"DEC errors not " f"realistic: std" f"={std_dec :.3f}"
    )

    true_peak_brightnesses = truth_df[SourceParams.PEAK].to_numpy()[idx]
    measured_peak_brightnesses = source_params_df[SourceParams.PEAK].to_numpy()
    measured_peak_brightnesses_err = source_params_df[
        SourceParams.PEAK_ERR
    ].to_numpy()

    # Compute normalized residuals
    norm_peak_resid = (
        measured_peak_brightnesses - true_peak_brightnesses
    ) / measured_peak_brightnesses_err

    # Check that the mean of the peak brightnesses is not biased
    t_stat_peak = ttest_1samp(norm_peak_resid, popmean=0)[0]
    assert (
        np.abs(t_stat_peak) < SCALED_MAX_BIAS
    ), f"Peak brightnesses severely biased: t_statistic = {t_stat_peak :.3f}"

    std_peak = np.std(norm_peak_resid)
    # Check standard deviation is ~1 (roughly Gaussian-distributed errors)
    assert (
        1.0 / STD_MAX_BIAS_FACTOR < std_peak < STD_MAX_BIAS_FACTOR
    ), f"Peak brightnesses not realistic: std={std_peak :.3f}"


if __name__ == "__main__":
    unittest.main()
